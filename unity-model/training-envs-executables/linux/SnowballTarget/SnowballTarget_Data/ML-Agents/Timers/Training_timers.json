{"count":1,"self":146.3876992,"total":314.331028,"children":{"InitializeActuators":{"count":11,"self":0.002028,"total":0.002028,"children":null},"InitializeSensors":{"count":11,"self":0.0021,"total":0.0021,"children":null},"AgentSendState":{"count":91067,"self":9.439999199999999,"total":18.098841999999998,"children":{"CollectObservations":{"count":200354,"self":0.034668,"total":0.034668,"children":null},"WriteActionMask":{"count":200354,"self":0.040177,"total":0.040177,"children":null},"RequestDecision":{"count":200354,"self":0.101521,"total":8.583998,"children":{"AgentInfo.ToProto":{"count":200354,"self":0.207471,"total":8.482477,"children":{"GenerateSensorData":{"count":200354,"self":7.6594999999999995,"total":8.275006,"children":{"RayPerceptionSensor.Perceive":{"count":801416,"self":0.615506,"total":0.615506,"children":null}}}}}}}}},"DecideAction":{"count":91067,"self":147.6965248,"total":147.696526,"children":null},"AgentAct":{"count":91067,"self":2.095936,"total":2.1416679999999997,"children":{"AgentInfo.ToProto":{"count":1001,"self":0.00065299999999999993,"total":0.045731999999999995,"children":{"GenerateSensorData":{"count":1001,"self":0.042009,"total":0.045079,"children":{"RayPerceptionSensor.Perceive":{"count":4004,"self":0.00307,"total":0.00307,"children":null}}}}}}}},"gauges":{"SnowballTarget.CumulativeReward":{"count":1001,"max":33,"min":0,"runningAverage":18.5674381,"value":33,"weightedAverage":27.9177761}},"metadata":{"timer_format_version":"0.1.0","start_time_seconds":"1744936934","unity_version":"2021.3.14f1","command_line_arguments":"\/app\/.\/training-envs-executables\/linux\/SnowballTarget\/SnowballTarget.x86_64 -nographics -batchmode --mlagents-port 5005 -logFile \/app\/results\/SnowballTarget1\/run_logs\/Player-0.log","communication_protocol_version":"1.5.0","com.unity.ml-agents_version":"2.1.0-exp.1","scene_name":"Training","end_time_seconds":"1744937248"}}